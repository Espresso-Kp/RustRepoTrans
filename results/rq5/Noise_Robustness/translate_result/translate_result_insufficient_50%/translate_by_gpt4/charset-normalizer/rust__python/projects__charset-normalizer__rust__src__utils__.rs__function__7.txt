<message>
please translate the given python function to rust according to the rust function signature, rust function realted variable, functions, and data type declarations and rust function dependency libraries I provide(delimited with XML tags). Only response the translated function results.
<python function>
def remove_accent(character: str) -> str:
    decomposed: str = unicodedata.decomposition(character)
    if not decomposed:
        return character

    codes: List[str] = decomposed.split(" ")

    return chr(int(codes[0], 16))
</python function>
<rust function signature>
pub(crate) fn remove_accent(ch: char) -> char 
</rust function signature>
<rust function realted variable, functions, and data type declarations>
fn next(&mut self) -> Option<Self::Item> {
        self.items.next()
    }

</rust function realted variable, functions, and data type declarations>
<rust function dependency libraries>


use crate::assets::LANGUAGES;
use crate::consts::{
    ENCODING_MARKS, IANA_SUPPORTED, IANA_SUPPORTED_SIMILAR, RE_POSSIBLE_ENCODING_INDICATION,
    UNICODE_RANGES_COMBINED, UNICODE_SECONDARY_RANGE_KEYWORD,
};
use crate::entity::Language;
use ahash::{HashSet, HashSetExt};
use encoding::label::encoding_from_whatwg_label;
use encoding::{CodecError, DecoderTrap, EncoderTrap, Encoding, EncodingRef, StringWriter};
use icu_normalizer::DecomposingNormalizer;
use unicode_names2::name;
use std::borrow::Cow;
use std::fs;
use std::path::{Path, PathBuf};

</rust function dependency libraries>

</message>
<function>
pub(crate) fn remove_accent(ch: char) -> char {
    DecomposingNormalizer::new_nfd() //initialize decomposer
        .normalize(ch.to_string().as_str()) //normalize into String
        .chars()
        .next() // retrieve first component(unaccented char)
        .unwrap_or(ch) //if fail, return the original char
}
</function>
<translated function>
Here is your translated `remove_accent` function from Python to Rust:

```rust
use icu_normalizer::DecomposingNormalizer;

pub(crate) fn remove_accent(ch: char) -> char {
    let mut decomposer = DecomposingNormalizer::default();
    let decomposed = decomposer.normalize(&String::from(ch)).as_str().to_string();

    match decomposed.contains(' ') {
        false => ch,
        true => {
            let mut codes = decomposed.trim().split_whitespace();
            match codes.next() {
                Some(code) => {
                    let value = i32::from_str_radix(code, 16).unwrap();
                    std::char::from_u32(value as u32).unwrap()
                }
                None => ch
            }
        }
    }
}
```

This function is using the `icu_normalizer` crate to decompose the character. Then it splits the decomposed string by white space. If the split yields a hexadecimal number (base 16), it is converted back into a char and returned.

Note: This code assumes that the decomposition will always result in a valid char when taking the first hexadecimal code. This may not always be the case, and proper error handling should be implemented depending on your specific use case.</translated function>Here is your translated `remove_accent` function from Python to Rust:

```rust
use icu_normalizer::DecomposingNormalizer;

pub(crate) fn remove_accent(ch: char) -> char {
    let mut decomposer = DecomposingNormalizer::default();
    let decomposed = decomposer.normalize(&String::from(ch)).as_str().to_string();

    match decomposed.contains(' ') {
        false => ch,
        true => {
            let mut codes = decomposed.trim().split_whitespace();
            match codes.next() {
                Some(code) => {
                    let value = i32::from_str_radix(code, 16).unwrap();
                    std::char::from_u32(value as u32).unwrap()
                }
                None => ch
            }
        }
    }
}
```

This function is using the `icu_normalizer` crate to decompose the character. Then it splits the decomposed string by white space. If the split yields a hexadecimal number (base 16), it is converted back into a char and returned.

Note: This code assumes that the decomposition will always result in a valid char when taking the first hexadecimal code. This may not always be the case, and proper error handling should be implemented depending on your specific use case.