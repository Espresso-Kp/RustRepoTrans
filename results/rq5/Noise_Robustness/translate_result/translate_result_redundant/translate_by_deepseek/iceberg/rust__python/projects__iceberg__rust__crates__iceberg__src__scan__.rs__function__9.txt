<message>
please translate the given python function to rust according to the rust function signature, rust function realted variable, functions, and data type declarations and rust function dependency libraries I provide(delimited with XML tags). Only response the translated function results.
<python function>
def plan_files(self) -> Iterable[FileScanTask]:
        """Plans the relevant files by filtering on the PartitionSpecs.

        Returns:
            List of FileScanTasks that contain both data and delete files.
        """
        snapshot = self.snapshot()
        if not snapshot:
            return iter([])

        # step 1: filter manifests using partition summaries
        # the filter depends on the partition spec used to write the manifest file, so create a cache of filters for each spec id

        manifest_evaluators: Dict[int, Callable[[ManifestFile], bool]] = KeyDefaultDict(self._build_manifest_evaluator)

        manifests = [
            manifest_file
            for manifest_file in snapshot.manifests(self.io)
            if manifest_evaluators[manifest_file.partition_spec_id](manifest_file)
        ]

        # step 2: filter the data files in each manifest
        # this filter depends on the partition spec used to write the manifest file

        partition_evaluators: Dict[int, Callable[[DataFile], bool]] = KeyDefaultDict(self._build_partition_evaluator)
        metrics_evaluator = _InclusiveMetricsEvaluator(
            self.table_metadata.schema(), self.row_filter, self.case_sensitive, self.options.get("include_empty_files") == "true"
        ).eval

        min_data_sequence_number = _min_data_file_sequence_number(manifests)

        data_entries: List[ManifestEntry] = []
        positional_delete_entries = SortedList(key=lambda entry: entry.data_sequence_number or INITIAL_SEQUENCE_NUMBER)

        executor = ExecutorFactory.get_or_create()
        for manifest_entry in chain(
            *executor.map(
                lambda args: _open_manifest(*args),
                [
                    (
                        self.io,
                        manifest,
                        partition_evaluators[manifest.partition_spec_id],
                        metrics_evaluator,
                    )
                    for manifest in manifests
                    if self._check_sequence_number(min_data_sequence_number, manifest)
                ],
            )
        ):
            data_file = manifest_entry.data_file
            if data_file.content == DataFileContent.DATA:
                data_entries.append(manifest_entry)
            elif data_file.content == DataFileContent.POSITION_DELETES:
                positional_delete_entries.add(manifest_entry)
            elif data_file.content == DataFileContent.EQUALITY_DELETES:
                raise ValueError("PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568")
            else:
                raise ValueError(f"Unknown DataFileContent ({data_file.content}): {manifest_entry}")

        return [
            FileScanTask(
                data_entry.data_file,
                delete_files=_match_deletes_to_data_file(
                    data_entry,
                    positional_delete_entries,
                ),
            )
            for data_entry in data_entries
        ]
</python function>
<rust function signature>
pub async fn plan_files(&self) -> Result<FileScanTaskStream> 
</rust function signature>
<rust function realted variable, functions, and data type declarations>
pub fn entries(&self) -> &[ManifestEntryRef] {
        &self.entries
    }

pub fn content_type(&self) -> DataContentType {
        self.content
    }

pub fn file_size_in_bytes(&self) -> u64 {
        self.file_size_in_bytes
    }

fn bound_filter(&self) -> Option<&BoundPredicate> {
        self.bound_filter.as_ref()
    }

pub fn file_path(&self) -> &str {
        &self.file_path
    }

pub fn filter(mut self, predicate: Predicate) -> Self {
        self.predicates = Some(predicate);
        self
    }

pub fn data_file(&self) -> &DataFile {
        &self.data_file
    }

pub(crate) fn eval(&self, data_file: &DataFile) -> Result<bool> {
        let mut visitor = ExpressionEvaluatorVisitor::new(self, data_file.partition());

        visit(&mut visitor, &self.partition_filter)
    }

fn get(&mut self, spec_id: i32, partition_filter: &BoundPredicate) -> &mut ExpressionEvaluator {
        self.0
            .entry(spec_id)
            .or_insert(ExpressionEvaluator::new(partition_filter.clone()))
    }

fn new(
        schema: SchemaRef,
        snapshot: SnapshotRef,
        table_metadata: TableMetadataRef,
        file_io: FileIO,
        filter: Option<Arc<Predicate>>,
        case_sensitive: bool,
    ) -> Result<Self> {
        let bound_filter = match filter {
            Some(ref filter) => Some(filter.bind(schema.clone(), case_sensitive)?),
            None => None,
        };

        Ok(Self {
            schema,
            snapshot,
            table_metadata,
            file_io,
            bound_filter,
            case_sensitive,
        })
    }

fn new() -> Self {
        Self(HashMap::new())
    }

fn new() -> Self {
        Self(HashMap::new())
    }

fn new() -> Self {
        Self(HashMap::new())
    }

fn content_type_is_data(entry: &ManifestFile) -> bool {
        if let ManifestContentType::Data = entry.content {
            return true;
        }
        false
    }

pub(crate) fn eval(
        filter: &'a BoundPredicate,
        data_file: &'a DataFile,
        include_empty_files: bool,
    ) -> crate::Result<bool> {
        if !include_empty_files && data_file.record_count == 0 {
            return ROWS_CANNOT_MATCH;
        }

        let mut evaluator = Self::new(data_file);
        visit(&mut evaluator, filter)
    }
    
pub struct TableScan {
    snapshot: SnapshotRef,
    table_metadata: TableMetadataRef,
    file_io: FileIO,
    column_names: Vec<String>,
    bound_predicates: Option<BoundPredicate>,
    schema: SchemaRef,
    batch_size: Option<usize>,
    case_sensitive: bool,
    filter: Option<Arc<Predicate>>,
}

struct FileScanStreamContext {
    schema: SchemaRef,
    snapshot: SnapshotRef,
    table_metadata: TableMetadataRef,
    file_io: FileIO,
    bound_filter: Option<BoundPredicate>,
    case_sensitive: bool,
}

struct PartitionFilterCache(HashMap<i32, BoundPredicate>);

struct ManifestEvaluatorCache(HashMap<i32, ManifestEvaluator>);

struct ExpressionEvaluatorCache(HashMap<i32, ExpressionEvaluator>);

pub enum ErrorKind {
    /// Iceberg don't know what happened here, and no actions other than
    /// just returning it back. For example, iceberg returns an internal
    /// service error.
    Unexpected,

    /// Iceberg data is invalid.
    ///
    /// This error is returned when we try to read a table from iceberg but
    /// failed to parse it's metadata or data file correctly.
    ///
    /// The table could be invalid or corrupted.
    DataInvalid,
    /// Iceberg feature is not supported.
    ///
    /// This error is returned when given iceberg feature is not supported.
    FeatureUnsupported,
}


pub enum DataContentType {
    /// value: 0
    Data = 0,
    /// value: 1
    PositionDeletes = 1,
    /// value: 2
    EqualityDeletes = 2,
}


pub fn entries(&self) -> &[ManifestFile] {
        &self.entries
    }
pub struct TableScan {
    snapshot: SnapshotRef,
    table_metadata: TableMetadataRef,
    file_io: FileIO,
    column_names: Vec<String>,
    bound_predicates: Option<BoundPredicate>,
    schema: SchemaRef,
    batch_size: Option<usize>,
    case_sensitive: bool,
    filter: Option<Arc<Predicate>>,
}

</rust function realted variable, functions, and data type declarations>
<rust function dependency libraries>

use crate::arrow::ArrowReaderBuilder;
use crate::expr::visitors::expression_evaluator::ExpressionEvaluator;
use crate::expr::visitors::inclusive_metrics_evaluator::InclusiveMetricsEvaluator;
use crate::expr::visitors::inclusive_projection::InclusiveProjection;
use crate::expr::visitors::manifest_evaluator::ManifestEvaluator;
use crate::expr::{Bind, BoundPredicate, Predicate};
use crate::io::FileIO;
use crate::spec::{
    DataContentType, ManifestContentType, ManifestFile, Schema, SchemaRef, SnapshotRef,
    TableMetadataRef,
};
use crate::table::Table;
use crate::{Error, ErrorKind, Result};
use arrow_array::RecordBatch;
use async_stream::try_stream;
use futures::stream::BoxStream;
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use std::collections::hash_map::Entry;
use std::collections::HashMap;
use std::sync::Arc;
use crate::expr::Reference;
use crate::io::{FileIO, OutputFile};
use crate::spec::{
        DataContentType, DataFileBuilder, DataFileFormat, Datum, FormatVersion, Literal, Manifest,
        ManifestContentType, ManifestEntry, ManifestListWriter, ManifestMetadata, ManifestStatus,
        ManifestWriter, Struct, TableMetadata, EMPTY_SNAPSHOT_ID,
    };
use crate::table::Table;
use crate::TableIdent;
use arrow_array::{ArrayRef, Int64Array, RecordBatch};
use futures::TryStreamExt;
use parquet::arrow::{ArrowWriter, PARQUET_FIELD_ID_META_KEY};
use parquet::basic::Compression;
use parquet::file::properties::WriterProperties;
use std::collections::HashMap;
use std::fs;
use std::fs::File;
use std::sync::Arc;
use tempfile::TempDir;
use tera::{Context, Tera};
use uuid::Uuid;

</rust function dependency libraries>

</message>
<function>
pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
        let context = FileScanStreamContext::new(
            self.schema.clone(),
            self.snapshot.clone(),
            self.table_metadata.clone(),
            self.file_io.clone(),
            self.filter.clone(),
            self.case_sensitive,
        )?;

        let mut partition_filter_cache = PartitionFilterCache::new();
        let mut manifest_evaluator_cache = ManifestEvaluatorCache::new();
        let mut expression_evaluator_cache = ExpressionEvaluatorCache::new();

        Ok(try_stream! {
            let manifest_list = context
                .snapshot
                .load_manifest_list(&context.file_io, &context.table_metadata)
                .await?;

            for entry in manifest_list.entries() {
                if !Self::content_type_is_data(entry) {
                    continue;
                }

                let partition_spec_id = entry.partition_spec_id;

                let partition_filter = partition_filter_cache.get(
                    partition_spec_id,
                    &context,
                )?;

                if let Some(partition_filter) = partition_filter {
                    let manifest_evaluator = manifest_evaluator_cache.get(
                        partition_spec_id,
                        partition_filter,
                    );

                    if !manifest_evaluator.eval(entry)? {
                        continue;
                    }
                }

                let manifest = entry.load_manifest(&context.file_io).await?;
                let mut manifest_entries_stream =
                    futures::stream::iter(manifest.entries().iter().filter(|e| e.is_alive()));

                while let Some(manifest_entry) = manifest_entries_stream.next().await {
                    let data_file = manifest_entry.data_file();

                    if let Some(partition_filter) = partition_filter {
                        let expression_evaluator = expression_evaluator_cache.get(partition_spec_id, partition_filter);

                        if !expression_evaluator.eval(data_file)? {
                            continue;
                        }
                    }


                    if let Some(bound_predicate) = context.bound_filter() {
                        // reject any manifest entries whose data file's metrics don't match the filter.
                        if !InclusiveMetricsEvaluator::eval(
                            bound_predicate,
                            manifest_entry.data_file(),
                            false
                        )? {
                            continue;
                        }
                    }

                    match manifest_entry.content_type() {
                        DataContentType::EqualityDeletes | DataContentType::PositionDeletes => {
                            yield Err(Error::new(
                                ErrorKind::FeatureUnsupported,
                                "Delete files are not supported yet.",
                            ))?;
                        }
                        DataContentType::Data => {
                            let scan_task: Result<FileScanTask> = Ok(FileScanTask {
                                data_file_path: manifest_entry.data_file().file_path().to_string(),
                                start: 0,
                                length: manifest_entry.file_size_in_bytes(),
                            });
                            yield scan_task?;
                        }
                    }
                }
            }
        }
        .boxed())
    }
</function>
<translated function>
 ```rust
use crate::arrow::ArrowReaderBuilder;
use crate::expr::visitors::expression_evaluator::ExpressionEvaluator;
use crate::expr::visitors::inclusive_metrics_evaluator::InclusiveMetricsEvaluator;
use crate::expr::visitors::inclusive_projection::InclusiveProjection;
use crate::expr::visitors::manifest_evaluator::ManifestEvaluator;
use crate::expr::{Bind, BoundPredicate, Predicate};
use crate::io::FileIO;
use crate::spec::{
    DataContentType, ManifestContentType, ManifestFile, Schema, SchemaRef, SnapshotRef,
    TableMetadataRef,
};
use crate::table::Table;
use crate::{Error, ErrorKind, Result};
use arrow_array::RecordBatch;
use async_stream::try_stream;
use futures::stream::BoxStream;
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use std::collections::hash_map::Entry;
use std::collections::HashMap;
use std::sync::Arc;
use crate::expr::Reference;
use crate::io::{FileIO, OutputFile};
use crate::spec::{
        DataContentType, DataFileBuilder, DataFileFormat, Datum, FormatVersion, Literal, Manifest,
        ManifestContentType, ManifestEntry, ManifestListWriter, ManifestMetadata, ManifestStatus,
        ManifestWriter, Struct, TableMetadata, EMPTY_SNAPSHOT_ID,
    };
use crate::table::Table;
use crate::TableIdent;
use arrow_array::{ArrayRef, Int64Array, RecordBatch};
use futures::TryStreamExt;
use parquet::arrow::{ArrowWriter, PARQUET_FIELD_ID_META_KEY};
use parquet::basic::Compression;
use parquet::file::properties::WriterProperties;
use std::collections::HashMap;
use std::fs;
use std::fs::File;
use std::sync::Arc;
use tempfile::TempDir;
use tera::{Context, Tera};
use uuid::Uuid;

pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
    let snapshot = self.snapshot();
    if snapshot.is_none() {
        return Ok(Box::pin(try_stream! {
            yield FileScanTask::default();
        }));
    }

    let snapshot = snapshot.unwrap();

    // step 1: filter manifests using partition summaries
    let mut manifest_evaluators: HashMap<i32, ManifestEvaluator> = HashMap::new();
    let manifests = snapshot.manifests(self.io()).filter(|manifest_file| {
        let evaluator = manifest_evaluators.entry(manifest_file.partition_spec_id()).unwrap_or_else(|| {
            self._build_manifest_evaluator(manifest_file.partition_spec_id())
        });
        evaluator(manifest_file)
    }).collect();

    // step 2: filter the data files in each manifest
    let mut partition_evaluators: HashMap<i32, Box<dyn Fn(&DataFile) -> bool>> = HashMap::new();
    let metrics_evaluator = InclusiveMetricsEvaluator::new(
        self.table_metadata().schema().clone(),
        self.row_filter(),
        self.case_sensitive(),
        self.options().get("include_empty_files") == Some("true"),
    ).eval;

    let min_data_sequence_number = _min_data_file_sequence_number(&manifests);

    let mut data_entries: Vec<ManifestEntry> = Vec::new();
    let mut positional_delete_entries = SortedList::new();

    let executor = ExecutorFactory::get_or_create();
    let tasks = executor.map(
        |args| _open_manifest(*args),
        manifests.into_iter().filter_map(|manifest| {
            if self._check_sequence_number(min_data_sequence_number, &manifest) {
                Some((
                    self.io(),
                    manifest,
                    partition_evaluators.entry(manifest.partition_spec_id()).unwrap_or_else(|| {
                        self._build_partition_evaluator(manifest.partition_spec_id())
                    }),
                    metrics_evaluator,
                ))
            } else {
                None
            }
        }).collect(),
    ).filter_map(|manifest_entry| {
        let data_file = manifest_entry.data_file();
        if data_file.content == DataFileContent::DATA {
            Some(manifest_entry)
        } else {
            None
        }
    }).collect();

    Ok(Box::pin(try_stream! {
        for data_entry in data_entries {
            yield FileScanTask {
                data_file: data_entry.data_file().clone(),
                delete_files: _match_deletes_to_data_file(data_entry, &positional_delete_entries),
            };
        }
    }))
}
```</translated function> ```rust
use crate::arrow::ArrowReaderBuilder;
use crate::expr::visitors::expression_evaluator::ExpressionEvaluator;
use crate::expr::visitors::inclusive_metrics_evaluator::InclusiveMetricsEvaluator;
use crate::expr::visitors::inclusive_projection::InclusiveProjection;
use crate::expr::visitors::manifest_evaluator::ManifestEvaluator;
use crate::expr::{Bind, BoundPredicate, Predicate};
use crate::io::FileIO;
use crate::spec::{
    DataContentType, ManifestContentType, ManifestFile, Schema, SchemaRef, SnapshotRef,
    TableMetadataRef,
};
use crate::table::Table;
use crate::{Error, ErrorKind, Result};
use arrow_array::RecordBatch;
use async_stream::try_stream;
use futures::stream::BoxStream;
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use std::collections::hash_map::Entry;
use std::collections::HashMap;
use std::sync::Arc;
use crate::expr::Reference;
use crate::io::{FileIO, OutputFile};
use crate::spec::{
        DataContentType, DataFileBuilder, DataFileFormat, Datum, FormatVersion, Literal, Manifest,
        ManifestContentType, ManifestEntry, ManifestListWriter, ManifestMetadata, ManifestStatus,
        ManifestWriter, Struct, TableMetadata, EMPTY_SNAPSHOT_ID,
    };
use crate::table::Table;
use crate::TableIdent;
use arrow_array::{ArrayRef, Int64Array, RecordBatch};
use futures::TryStreamExt;
use parquet::arrow::{ArrowWriter, PARQUET_FIELD_ID_META_KEY};
use parquet::basic::Compression;
use parquet::file::properties::WriterProperties;
use std::collections::HashMap;
use std::fs;
use std::fs::File;
use std::sync::Arc;
use tempfile::TempDir;
use tera::{Context, Tera};
use uuid::Uuid;

pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
    let snapshot = self.snapshot();
    if snapshot.is_none() {
        return Ok(Box::pin(try_stream! {
            yield FileScanTask::default();
        }));
    }

    let snapshot = snapshot.unwrap();

    // step 1: filter manifests using partition summaries
    let mut manifest_evaluators: HashMap<i32, ManifestEvaluator> = HashMap::new();
    let manifests = snapshot.manifests(self.io()).filter(|manifest_file| {
        let evaluator = manifest_evaluators.entry(manifest_file.partition_spec_id()).unwrap_or_else(|| {
            self._build_manifest_evaluator(manifest_file.partition_spec_id())
        });
        evaluator(manifest_file)
    }).collect();

    // step 2: filter the data files in each manifest
    let mut partition_evaluators: HashMap<i32, Box<dyn Fn(&DataFile) -> bool>> = HashMap::new();
    let metrics_evaluator = InclusiveMetricsEvaluator::new(
        self.table_metadata().schema().clone(),
        self.row_filter(),
        self.case_sensitive(),
        self.options().get("include_empty_files") == Some("true"),
    ).eval;

    let min_data_sequence_number = _min_data_file_sequence_number(&manifests);

    let mut data_entries: Vec<ManifestEntry> = Vec::new();
    let mut positional_delete_entries = SortedList::new();

    let executor = ExecutorFactory::get_or_create();
    let tasks = executor.map(
        |args| _open_manifest(*args),
        manifests.into_iter().filter_map(|manifest| {
            if self._check_sequence_number(min_data_sequence_number, &manifest) {
                Some((
                    self.io(),
                    manifest,
                    partition_evaluators.entry(manifest.partition_spec_id()).unwrap_or_else(|| {
                        self._build_partition_evaluator(manifest.partition_spec_id())
                    }),
                    metrics_evaluator,
                ))
            } else {
                None
            }
        }).collect(),
    ).filter_map(|manifest_entry| {
        let data_file = manifest_entry.data_file();
        if data_file.content == DataFileContent::DATA {
            Some(manifest_entry)
        } else {
            None
        }
    }).collect();

    Ok(Box::pin(try_stream! {
        for data_entry in data_entries {
            yield FileScanTask {
                data_file: data_entry.data_file().clone(),
                delete_files: _match_deletes_to_data_file(data_entry, &positional_delete_entries),
            };
        }
    }))
}
```