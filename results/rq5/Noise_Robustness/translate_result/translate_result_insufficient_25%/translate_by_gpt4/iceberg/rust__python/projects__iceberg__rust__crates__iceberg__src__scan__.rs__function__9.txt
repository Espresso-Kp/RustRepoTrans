<message>
please translate the given python function to rust according to the rust function signature, rust function realted variable, functions, and data type declarations and rust function dependency libraries I provide(delimited with XML tags). Only response the translated function results.
<python function>
def plan_files(self) -> Iterable[FileScanTask]:
        """Plans the relevant files by filtering on the PartitionSpecs.

        Returns:
            List of FileScanTasks that contain both data and delete files.
        """
        snapshot = self.snapshot()
        if not snapshot:
            return iter([])

        # step 1: filter manifests using partition summaries
        # the filter depends on the partition spec used to write the manifest file, so create a cache of filters for each spec id

        manifest_evaluators: Dict[int, Callable[[ManifestFile], bool]] = KeyDefaultDict(self._build_manifest_evaluator)

        manifests = [
            manifest_file
            for manifest_file in snapshot.manifests(self.io)
            if manifest_evaluators[manifest_file.partition_spec_id](manifest_file)
        ]

        # step 2: filter the data files in each manifest
        # this filter depends on the partition spec used to write the manifest file

        partition_evaluators: Dict[int, Callable[[DataFile], bool]] = KeyDefaultDict(self._build_partition_evaluator)
        metrics_evaluator = _InclusiveMetricsEvaluator(
            self.table_metadata.schema(), self.row_filter, self.case_sensitive, self.options.get("include_empty_files") == "true"
        ).eval

        min_data_sequence_number = _min_data_file_sequence_number(manifests)

        data_entries: List[ManifestEntry] = []
        positional_delete_entries = SortedList(key=lambda entry: entry.data_sequence_number or INITIAL_SEQUENCE_NUMBER)

        executor = ExecutorFactory.get_or_create()
        for manifest_entry in chain(
            *executor.map(
                lambda args: _open_manifest(*args),
                [
                    (
                        self.io,
                        manifest,
                        partition_evaluators[manifest.partition_spec_id],
                        metrics_evaluator,
                    )
                    for manifest in manifests
                    if self._check_sequence_number(min_data_sequence_number, manifest)
                ],
            )
        ):
            data_file = manifest_entry.data_file
            if data_file.content == DataFileContent.DATA:
                data_entries.append(manifest_entry)
            elif data_file.content == DataFileContent.POSITION_DELETES:
                positional_delete_entries.add(manifest_entry)
            elif data_file.content == DataFileContent.EQUALITY_DELETES:
                raise ValueError("PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568")
            else:
                raise ValueError(f"Unknown DataFileContent ({data_file.content}): {manifest_entry}")

        return [
            FileScanTask(
                data_entry.data_file,
                delete_files=_match_deletes_to_data_file(
                    data_entry,
                    positional_delete_entries,
                ),
            )
            for data_entry in data_entries
        ]
</python function>
<rust function signature>
pub async fn plan_files(&self) -> Result<FileScanTaskStream> 
</rust function signature>
<rust function realted variable, functions, and data type declarations>
pub fn content_type(&self) -> DataContentType {
        self.content
    }
pub fn file_path(&self) -> &str {
        &self.file_path
    }
pub fn data_file(&self) -> &DataFile {
        &self.data_file
    }
fn new() -> Self {
        Self(HashMap::new())
    }
pub(crate) fn eval(
        filter: &'a BoundPredicate,
        data_file: &'a DataFile,
        include_empty_files: bool,
    ) -> crate::Result<bool> {
        if !include_empty_files && data_file.record_count == 0 {
            return ROWS_CANNOT_MATCH;
        }

        let mut evaluator = Self::new(data_file);
        visit(&mut evaluator, filter)
    }
struct PartitionFilterCache(HashMap<i32, BoundPredicate>);

</rust function realted variable, functions, and data type declarations>
<rust function dependency libraries>



use crate::arrow::ArrowReaderBuilder;
use crate::expr::visitors::expression_evaluator::ExpressionEvaluator;
use crate::expr::visitors::inclusive_metrics_evaluator::InclusiveMetricsEvaluator;
use crate::expr::visitors::inclusive_projection::InclusiveProjection;
use crate::expr::visitors::manifest_evaluator::ManifestEvaluator;
use crate::expr::{Bind, BoundPredicate, Predicate};
use crate::io::FileIO;
use crate::spec::{
    DataContentType, ManifestContentType, ManifestFile, Schema, SchemaRef, SnapshotRef,
    TableMetadataRef,
};
use crate::table::Table;
use crate::{Error, ErrorKind, Result};
use arrow_array::RecordBatch;
use async_stream::try_stream;
use futures::stream::BoxStream;
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use std::collections::hash_map::Entry;
use std::collections::HashMap;
use std::sync::Arc;
use crate::expr::Reference;
use crate::io::{FileIO, OutputFile};
use crate::spec::{
        DataContentType, DataFileBuilder, DataFileFormat, Datum, FormatVersion, Literal, Manifest,
        ManifestContentType, ManifestEntry, ManifestListWriter, ManifestMetadata, ManifestStatus,
        ManifestWriter, Struct, TableMetadata, EMPTY_SNAPSHOT_ID,
    };
use crate::table::Table;
use crate::TableIdent;
use arrow_array::{ArrayRef, Int64Array, RecordBatch};
use futures::TryStreamExt;
use parquet::arrow::{ArrowWriter, PARQUET_FIELD_ID_META_KEY};
use parquet::basic::Compression;
use parquet::file::properties::WriterProperties;
use std::collections::HashMap;
use std::fs;
use std::fs::File;
use std::sync::Arc;
use tempfile::TempDir;
use tera::{Context, Tera};
use uuid::Uuid;

</rust function dependency libraries>

</message>
<function>
pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
        let context = FileScanStreamContext::new(
            self.schema.clone(),
            self.snapshot.clone(),
            self.table_metadata.clone(),
            self.file_io.clone(),
            self.filter.clone(),
            self.case_sensitive,
        )?;

        let mut partition_filter_cache = PartitionFilterCache::new();
        let mut manifest_evaluator_cache = ManifestEvaluatorCache::new();
        let mut expression_evaluator_cache = ExpressionEvaluatorCache::new();

        Ok(try_stream! {
            let manifest_list = context
                .snapshot
                .load_manifest_list(&context.file_io, &context.table_metadata)
                .await?;

            for entry in manifest_list.entries() {
                if !Self::content_type_is_data(entry) {
                    continue;
                }

                let partition_spec_id = entry.partition_spec_id;

                let partition_filter = partition_filter_cache.get(
                    partition_spec_id,
                    &context,
                )?;

                if let Some(partition_filter) = partition_filter {
                    let manifest_evaluator = manifest_evaluator_cache.get(
                        partition_spec_id,
                        partition_filter,
                    );

                    if !manifest_evaluator.eval(entry)? {
                        continue;
                    }
                }

                let manifest = entry.load_manifest(&context.file_io).await?;
                let mut manifest_entries_stream =
                    futures::stream::iter(manifest.entries().iter().filter(|e| e.is_alive()));

                while let Some(manifest_entry) = manifest_entries_stream.next().await {
                    let data_file = manifest_entry.data_file();

                    if let Some(partition_filter) = partition_filter {
                        let expression_evaluator = expression_evaluator_cache.get(partition_spec_id, partition_filter);

                        if !expression_evaluator.eval(data_file)? {
                            continue;
                        }
                    }


                    if let Some(bound_predicate) = context.bound_filter() {
                        // reject any manifest entries whose data file's metrics don't match the filter.
                        if !InclusiveMetricsEvaluator::eval(
                            bound_predicate,
                            manifest_entry.data_file(),
                            false
                        )? {
                            continue;
                        }
                    }

                    match manifest_entry.content_type() {
                        DataContentType::EqualityDeletes | DataContentType::PositionDeletes => {
                            yield Err(Error::new(
                                ErrorKind::FeatureUnsupported,
                                "Delete files are not supported yet.",
                            ))?;
                        }
                        DataContentType::Data => {
                            let scan_task: Result<FileScanTask> = Ok(FileScanTask {
                                data_file_path: manifest_entry.data_file().file_path().to_string(),
                                start: 0,
                                length: manifest_entry.file_size_in_bytes(),
                            });
                            yield scan_task?;
                        }
                    }
                }
            }
        }
        .boxed())
    }
</function>
<translated function>
Here is the translated Rust code that uses similar constructs and concepts from the Python function including decision branching, looping over iterators, and async processing, please note that the Python version uses Executor to process tasks in parallel, while the Rust version uses async functionality for concurrent processing:

```rust
use futures::stream::{FuturesUnordered, StreamExt};


pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
    let snapshot = self.snapshot().await?;
    if snapshot.is_none() {
        return Ok(FileScanTaskStream::from(vec![]));
    }
    let snapshot = snapshot.unwrap();

    let manifest_evaluators = KeyDefaultDict::new(self._build_manifest_evaluator);

    let mut planning_stream = FuturesUnordered::new();

    for manifest in snapshot.manifests(&self.io).await? {
        if manifest_evaluators[manifest.partition_spec_id](&manifest).await? {
            planning_stream.push(manifest);
        }
    }

    let mut min_data_sequence_number = None;

    while let Some(manifest) = planning_stream.next().await {
        if min_data_sequence_number.is_none() || min_data_sequence_number.unwrap() > manifest.sequence_number {
            min_data_sequence_number = Some(manifest.sequence_number);
        }
    }

    let partition_evaluators = KeyDefaultDict::new(self._build_partition_evaluator);

    let metrics_evaluator = InclusiveMetricsEvaluator::new(&self.table_metadata.schema(), &self.row_filter, self.case_sensitive, self.options.get("include_empty_files").unwrap_or(&"false".to_string()) == "true").eval;

    for manifest in planning_stream.into_iter() {

        let sequence_number_check = self._check_sequence_number(min_data_sequence_number.unwrap(), &manifest);

        if sequence_number_check {

            let entries_result = match self.entries_result(manifest.file_path()) {
                Ok(entries) => entries,
                Err(error) => {
                    return Err(error);
                },
            };

            let positional_delete_entries = SortedList::new();

            let evaluated_entries = partition_evaluators[manifest.partition_spec_id](&entries_result);

            for manifest_entry in evaluated_entries {

                let content = manifest_entry.content_type();

                if content == DataContentType::Data {
                    data_entries.push(manifest_entry);
                } else if content == DataContentType::PositionDeletes {
                    positional_delete_entries.add(manifest_entry);
                } else if content == DataContentType::EqualityDeletes {
                    return Err(ErrorKind::NotYetImplemented("PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568").into());
                } else {
                    return Err(ErrorKind::UnknownDataContent(content).into());
                }
            }
        }
    }

    let mut file_scan_task_stream = FileScanTaskStream::new();

    for data_entry in data_entries {
        let file_scan_task = FileScanTask::new(&data_entry.data_file(), _match_deletes_to_data_file(&data_entry, &positional_delete_entries));
        file_scan_task_stream.push(file_scan_task);
    }

    Ok(file_scan_task_stream)
}
```
Please note that some additional code modification might be needed to fit your specific Rust codebase/environment.</translated function>Here is the translated Rust code that uses similar constructs and concepts from the Python function including decision branching, looping over iterators, and async processing, please note that the Python version uses Executor to process tasks in parallel, while the Rust version uses async functionality for concurrent processing:

```rust
use futures::stream::{FuturesUnordered, StreamExt};


pub async fn plan_files(&self) -> Result<FileScanTaskStream> {
    let snapshot = self.snapshot().await?;
    if snapshot.is_none() {
        return Ok(FileScanTaskStream::from(vec![]));
    }
    let snapshot = snapshot.unwrap();

    let manifest_evaluators = KeyDefaultDict::new(self._build_manifest_evaluator);

    let mut planning_stream = FuturesUnordered::new();

    for manifest in snapshot.manifests(&self.io).await? {
        if manifest_evaluators[manifest.partition_spec_id](&manifest).await? {
            planning_stream.push(manifest);
        }
    }

    let mut min_data_sequence_number = None;

    while let Some(manifest) = planning_stream.next().await {
        if min_data_sequence_number.is_none() || min_data_sequence_number.unwrap() > manifest.sequence_number {
            min_data_sequence_number = Some(manifest.sequence_number);
        }
    }

    let partition_evaluators = KeyDefaultDict::new(self._build_partition_evaluator);

    let metrics_evaluator = InclusiveMetricsEvaluator::new(&self.table_metadata.schema(), &self.row_filter, self.case_sensitive, self.options.get("include_empty_files").unwrap_or(&"false".to_string()) == "true").eval;

    for manifest in planning_stream.into_iter() {

        let sequence_number_check = self._check_sequence_number(min_data_sequence_number.unwrap(), &manifest);

        if sequence_number_check {

            let entries_result = match self.entries_result(manifest.file_path()) {
                Ok(entries) => entries,
                Err(error) => {
                    return Err(error);
                },
            };

            let positional_delete_entries = SortedList::new();

            let evaluated_entries = partition_evaluators[manifest.partition_spec_id](&entries_result);

            for manifest_entry in evaluated_entries {

                let content = manifest_entry.content_type();

                if content == DataContentType::Data {
                    data_entries.push(manifest_entry);
                } else if content == DataContentType::PositionDeletes {
                    positional_delete_entries.add(manifest_entry);
                } else if content == DataContentType::EqualityDeletes {
                    return Err(ErrorKind::NotYetImplemented("PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568").into());
                } else {
                    return Err(ErrorKind::UnknownDataContent(content).into());
                }
            }
        }
    }

    let mut file_scan_task_stream = FileScanTaskStream::new();

    for data_entry in data_entries {
        let file_scan_task = FileScanTask::new(&data_entry.data_file(), _match_deletes_to_data_file(&data_entry, &positional_delete_entries));
        file_scan_task_stream.push(file_scan_task);
    }

    Ok(file_scan_task_stream)
}
```
Please note that some additional code modification might be needed to fit your specific Rust codebase/environment.