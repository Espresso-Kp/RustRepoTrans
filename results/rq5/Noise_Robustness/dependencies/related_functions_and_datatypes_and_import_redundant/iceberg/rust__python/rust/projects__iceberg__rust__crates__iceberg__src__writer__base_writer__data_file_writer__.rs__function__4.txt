async fn write(&mut self, batch: RecordBatch) -> Result<()> {
        self.inner_writer.as_mut().unwrap().write(&batch).await
    }

pub struct DataFileWriter<B: FileWriterBuilder> {
    inner_writer: Option<B::R>,
    partition_value: Struct,
}


fn before_struct_field(&mut self, _field: &iceberg::spec::NestedFieldRef) -> Result<()> {
        self.depth += 1;
        Ok(())
    }
pub struct DataFileWriter<B: FileWriterBuilder> {
    inner_writer: Option<B::R>,
    partition_value: Struct,
}
------

use crate::spec::{DataContentType, DataFile, Struct};
use crate::writer::file_writer::FileWriter;
use crate::writer::CurrentFileStatus;
use crate::writer::{file_writer::FileWriterBuilder, IcebergWriter, IcebergWriterBuilder};
use crate::Result;
use arrow_array::RecordBatch;
use itertools::Itertools;
use std::{collections::HashMap, sync::Arc};
use arrow_array::{types::Int64Type, ArrayRef, Int64Array, RecordBatch, StructArray};
use parquet::{arrow::PARQUET_FIELD_ID_META_KEY, file::properties::WriterProperties};
use tempfile::TempDir;
use crate::{
        io::FileIOBuilder,
        spec::DataFileFormat,
        writer::{
            base_writer::data_file_writer::{DataFileWriterBuilder, DataFileWriterConfig},
            file_writer::{
                location_generator::{test::MockLocationGenerator, DefaultFileNameGenerator},
                ParquetWriterBuilder,
            },
            tests::check_parquet_data_file,
            IcebergWriter, IcebergWriterBuilder,
        },
    };
