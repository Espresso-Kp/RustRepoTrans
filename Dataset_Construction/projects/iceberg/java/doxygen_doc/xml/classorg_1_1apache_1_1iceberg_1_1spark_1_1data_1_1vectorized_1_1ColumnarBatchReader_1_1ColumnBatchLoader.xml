<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.17">
  <compounddef id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader" kind="class" language="Java" prot="private">
    <compoundname>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</compoundname>
      <sectiondef kind="private-attrib">
      <memberdef kind="variable" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1add087b029a97b226defb6187d11490bf" prot="private" static="no" mutable="no">
        <type>final int</type>
        <definition>final int org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader::numRowsToRead</definition>
        <argsstring></argsstring>
        <name>numRowsToRead</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="78" column="23" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="78" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ac84947b923fdfbd399f48f41442779ca" prot="private" static="no" mutable="no">
        <type>int[]</type>
        <definition>int [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.rowIdMapping</definition>
        <argsstring></argsstring>
        <name>rowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="81" column="17" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="81" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae3d4725807305e7092bf34b9a05a1ac3" prot="private" static="no" mutable="no">
        <type>boolean[]</type>
        <definition>boolean [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.isDeleted</definition>
        <argsstring></argsstring>
        <name>isDeleted</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="84" column="21" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="84" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="package-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.ColumnBatchLoader</definition>
        <argsstring>(int numRowsToRead)</argsstring>
        <name>ColumnBatchLoader</name>
        <param>
          <type>int</type>
          <declname>numRowsToRead</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="86" column="5" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="86" bodyend="93"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnarBatch</type>
        <definition>ColumnarBatch org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.loadDataToColumnBatch</definition>
        <argsstring>()</argsstring>
        <name>loadDataToColumnBatch</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="95" column="19" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="95" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnVector[]</type>
        <definition>ColumnVector [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.readDataToColumnVectors</definition>
        <argsstring>()</argsstring>
        <name>readDataToColumnVectors</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="118" column="18" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="118" bodyend="137"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>boolean org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.hasEqDeletes</definition>
        <argsstring>()</argsstring>
        <name>hasEqDeletes</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="139" column="13" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="139" bodyend="141"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int</type>
        <definition>int org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="143" column="9" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="143" bodyend="152"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.posDelRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>posDelRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="154" column="10" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="154" bodyend="160"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.buildPosDelRowIdMapping</definition>
        <argsstring>(PositionDeleteIndex deletedRowPositions)</argsstring>
        <name>buildPosDelRowIdMapping</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1deletes_1_1PositionDeleteIndex" kindref="compound">PositionDeleteIndex</ref></type>
          <declname>deletedRowPositions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Build a row id mapping inside a batch, which skips deleted rows. Here is an example of how we delete 2 rows in a batch with 8 rows in total. [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>deletedRowPositions</parametername>
</parameternamelist>
<parameterdescription>
<para>a set of deleted row positions </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>the mapping array and the new num of rows in a batch, null if no row is deleted </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="172" column="10" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="172" bodyend="200"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int[]</type>
        <definition>int [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initEqDeleteRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initEqDeleteRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="202" column="9" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="202" bodyend="212"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>void org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.applyEqDelete</definition>
        <argsstring>(ColumnarBatch columnarBatch)</argsstring>
        <name>applyEqDelete</name>
        <param>
          <type>ColumnarBatch</type>
          <declname>columnarBatch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Filter out the equality deleted rows. Here is an example, [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes Equality delete 1 &lt;= x &lt;= 3 [0,4,5,7,-,-,-,-] <ndash/> After applying equality deletes [Set Num records to 4] [F,T,T,T,F,F,T,F] <ndash/> After applying equality deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>columnarBatch</parametername>
</parameternamelist>
<parameterdescription>
<para>the <ref refid="" kindref="compound">ColumnarBatch</ref> to apply the equality delete </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="224" column="10" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="224" bodyend="247"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.ColumnBatchLoader</definition>
        <argsstring>(int numRowsToRead)</argsstring>
        <name>ColumnBatchLoader</name>
        <param>
          <type>int</type>
          <declname>numRowsToRead</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="86" column="5" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="86" bodyend="93"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnarBatch</type>
        <definition>ColumnarBatch org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.loadDataToColumnBatch</definition>
        <argsstring>()</argsstring>
        <name>loadDataToColumnBatch</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="95" column="19" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="95" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnVector[]</type>
        <definition>ColumnVector [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.readDataToColumnVectors</definition>
        <argsstring>()</argsstring>
        <name>readDataToColumnVectors</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="118" column="18" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="118" bodyend="137"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>boolean org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.hasEqDeletes</definition>
        <argsstring>()</argsstring>
        <name>hasEqDeletes</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="139" column="13" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="139" bodyend="141"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int</type>
        <definition>int org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="143" column="9" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="143" bodyend="152"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.posDelRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>posDelRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="154" column="10" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="154" bodyend="160"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.buildPosDelRowIdMapping</definition>
        <argsstring>(PositionDeleteIndex deletedRowPositions)</argsstring>
        <name>buildPosDelRowIdMapping</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1deletes_1_1PositionDeleteIndex" kindref="compound">PositionDeleteIndex</ref></type>
          <declname>deletedRowPositions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Build a row id mapping inside a batch, which skips deleted rows. Here is an example of how we delete 2 rows in a batch with 8 rows in total. [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>deletedRowPositions</parametername>
</parameternamelist>
<parameterdescription>
<para>a set of deleted row positions </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>the mapping array and the new num of rows in a batch, null if no row is deleted </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="172" column="10" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="172" bodyend="200"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int[]</type>
        <definition>int [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initEqDeleteRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initEqDeleteRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="202" column="9" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="202" bodyend="212"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>void org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.applyEqDelete</definition>
        <argsstring>(ColumnarBatch columnarBatch)</argsstring>
        <name>applyEqDelete</name>
        <param>
          <type>ColumnarBatch</type>
          <declname>columnarBatch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Filter out the equality deleted rows. Here is an example, [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes Equality delete 1 &lt;= x &lt;= 3 [0,4,5,7,-,-,-,-] <ndash/> After applying equality deletes [Set Num records to 4] [F,T,T,T,F,F,T,F] <ndash/> After applying equality deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>columnarBatch</parametername>
</parameternamelist>
<parameterdescription>
<para>the <ref refid="" kindref="compound">ColumnarBatch</ref> to apply the equality delete </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="224" column="10" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="224" bodyend="247"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.ColumnBatchLoader</definition>
        <argsstring>(int numRowsToRead)</argsstring>
        <name>ColumnBatchLoader</name>
        <param>
          <type>int</type>
          <declname>numRowsToRead</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="86" column="5" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="86" bodyend="93"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnarBatch</type>
        <definition>ColumnarBatch org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.loadDataToColumnBatch</definition>
        <argsstring>()</argsstring>
        <name>loadDataToColumnBatch</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="95" column="19" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="95" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>ColumnVector[]</type>
        <definition>ColumnVector [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.readDataToColumnVectors</definition>
        <argsstring>()</argsstring>
        <name>readDataToColumnVectors</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="118" column="18" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="118" bodyend="137"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>boolean org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.hasEqDeletes</definition>
        <argsstring>()</argsstring>
        <name>hasEqDeletes</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="139" column="13" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="139" bodyend="141"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int</type>
        <definition>int org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="143" column="9" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="143" bodyend="152"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.posDelRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>posDelRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="154" column="10" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="154" bodyend="160"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1util_1_1Pair" kindref="compound">Pair</ref>&lt; int[], Integer &gt;</type>
        <definition>Pair&lt;int[], Integer&gt; org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.buildPosDelRowIdMapping</definition>
        <argsstring>(PositionDeleteIndex deletedRowPositions)</argsstring>
        <name>buildPosDelRowIdMapping</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1deletes_1_1PositionDeleteIndex" kindref="compound">PositionDeleteIndex</ref></type>
          <declname>deletedRowPositions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Build a row id mapping inside a batch, which skips deleted rows. Here is an example of how we delete 2 rows in a batch with 8 rows in total. [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>deletedRowPositions</parametername>
</parameternamelist>
<parameterdescription>
<para>a set of deleted row positions </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>the mapping array and the new num of rows in a batch, null if no row is deleted </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="172" column="10" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="172" bodyend="200"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>int[]</type>
        <definition>int [] org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.initEqDeleteRowIdMapping</definition>
        <argsstring>()</argsstring>
        <name>initEqDeleteRowIdMapping</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="202" column="9" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="202" bodyend="212"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>void org.apache.iceberg.spark.data.vectorized.ColumnarBatchReader.ColumnBatchLoader.applyEqDelete</definition>
        <argsstring>(ColumnarBatch columnarBatch)</argsstring>
        <name>applyEqDelete</name>
        <param>
          <type>ColumnarBatch</type>
          <declname>columnarBatch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Filter out the equality deleted rows. Here is an example, [0,1,2,3,4,5,6,7] <ndash/> Original status of the row id mapping array [F,F,F,F,F,F,F,F] <ndash/> Original status of the isDeleted array Position delete 2, 6 [0,1,3,4,5,7,-,-] <ndash/> After applying position deletes [Set Num records to 6] [F,F,T,F,F,F,T,F] <ndash/> After applying position deletes Equality delete 1 &lt;= x &lt;= 3 [0,4,5,7,-,-,-,-] <ndash/> After applying equality deletes [Set Num records to 4] [F,T,T,T,F,F,T,F] <ndash/> After applying equality deletes</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>columnarBatch</parametername>
</parameternamelist>
<parameterdescription>
<para>the <ref refid="" kindref="compound">ColumnarBatch</ref> to apply the equality delete </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="224" column="10" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="224" bodyend="247"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" line="77" column="34" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/data/vectorized/ColumnarBatchReader.java" bodystart="77" bodyend="248"/>
    <listofallmembers>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>applyEqDelete</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>applyEqDelete</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4d174eb39b129b8d40826d1847f5a979" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>applyEqDelete</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>buildPosDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>buildPosDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a047f472dd1fcf2a4102980e7b981b0b9" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>buildPosDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>ColumnBatchLoader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>ColumnBatchLoader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a90f600b53d50ce93db57ccf8f0a75d28" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>ColumnBatchLoader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>hasEqDeletes</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>hasEqDeletes</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a9dd28502277f6acb82f54bd9070b84e7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>hasEqDeletes</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initEqDeleteRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initEqDeleteRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a63d9009c7c1d1014b58641b834721e43" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initEqDeleteRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a4bb893cbadc56d8b2b36eb17a3253201" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>initRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae3d4725807305e7092bf34b9a05a1ac3" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>isDeleted</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>loadDataToColumnBatch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>loadDataToColumnBatch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a671e71e7fbeca867a2722c471ca49841" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>loadDataToColumnBatch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1add087b029a97b226defb6187d11490bf" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>numRowsToRead</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>posDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>posDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1a05271d702b842148109219bef0d41d3b" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>posDelRowIdMapping</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>readDataToColumnVectors</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>readDataToColumnVectors</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ae4dc2f659b85ac0f42604f337b4731b7" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>readDataToColumnVectors</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1data_1_1vectorized_1_1ColumnarBatchReader_1_1ColumnBatchLoader_1ac84947b923fdfbd399f48f41442779ca" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::data::vectorized::ColumnarBatchReader::ColumnBatchLoader</scope><name>rowIdMapping</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
