<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.17">
  <compounddef id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil" kind="class" language="Java" prot="public">
    <compoundname>org::apache::iceberg::spark::SparkTableUtil</compoundname>
    <innerclass refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" prot="public">org::apache::iceberg::spark::SparkTableUtil::SparkPartition</innerclass>
      <sectiondef kind="private-static-attrib">
      <memberdef kind="variable" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a701fbb8197f26a0464822d0aa3093efa" prot="private" static="yes" mutable="no">
        <type>final String</type>
        <definition>static final String org.apache.iceberg.spark.SparkTableUtil::DUPLICATE_FILE_MESSAGE</definition>
        <argsstring></argsstring>
        <name>DUPLICATE_FILE_MESSAGE</name>
        <initializer>=
      &quot;Cannot complete import because data files &quot;
          + &quot;to be imported already exist within the target table: %s.  &quot;
          + &quot;This is disabled by default as Iceberg is not designed for multiple references to the same file&quot;
          + &quot; within the same table.  If you are sure, you may set &apos;check_duplicate_files&apos; to false to force the import.&quot;</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="110" column="31" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="110" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="private-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.SparkTableUtil.SparkTableUtil</definition>
        <argsstring>()</argsstring>
        <name>SparkTableUtil</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="116" column="11" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="116" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.SparkTableUtil.SparkTableUtil</definition>
        <argsstring>()</argsstring>
        <name>SparkTableUtil</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="116" column="11" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="116" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.SparkTableUtil.SparkTableUtil</definition>
        <argsstring>()</argsstring>
        <name>SparkTableUtil</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="116" column="11" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="116" bodyend="116"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="public-static-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDF</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>partitionDF</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition in the table.</para>
<para>The DataFrame has 3 columns, partition key (a=1/b=2), partition location, and format (avro or parquet).</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="128" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="128" bodyend="133"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDFByFilter</definition>
        <argsstring>(SparkSession spark, String table, String expression)</argsstring>
        <name>partitionDFByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>expression</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition that matches the specified &apos;expression&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>name of the table. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>expression</parametername>
</parameternamelist>
<parameterdescription>
<para>The expression whose matching partitions are returned. </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table partitions. </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="143" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="143" bodyend="149"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="158" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="158" bodyend="166"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>partition filter, or null if no filter </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="176" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="176" bodyend="203"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, String table, String predicate)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>predicate</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicate</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="213" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="213" bodyend="233"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Expression predicateExpr)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>predicateExpr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicateExpr</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate expression on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="243" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="243" bodyend="273"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a7b75e0408be23eda1b7dec6c73f0bb19" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;</type>
        <definition>static List&lt;DataFile&gt; org.apache.iceberg.spark.SparkTableUtil.listPartition</definition>
        <argsstring>(SparkPartition partition, PartitionSpec spec, SerializableConfiguration conf, MetricsConfig metricsConfig)</argsstring>
        <name>listPartition</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
          <declname>partition</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1MetricsConfig" kindref="compound">MetricsConfig</ref></type>
          <declname>metricsConfig</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns the data files in a partition by listing the partition location.</para>
<para>For Parquet and ORC partitions, this will read metrics from the file footer. For Avro partitions, metrics are set to null.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>partition</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>conf</parametername>
</parameternamelist>
<parameterdescription>
<para>a serializable Hadoop conf </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>metricsConfig</parametername>
</parameternamelist>
<parameterdescription>
<para>a metrics conf </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a List of <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> </para>
</simplesect>
<xrefsect id="deprecated_1_deprecated000063"><xreftitle>Deprecated</xreftitle><xrefdescription><para>use <ref refid="" kindref="compound">String, String, PartitionSpec, Configuration, MetricsConfig, NameMapping)</ref> </para>
</xrefdescription></xrefsect></para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="289" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="289" bodyend="295"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab6335c5079cb1e674019784cf50a0776" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;</type>
        <definition>static List&lt;DataFile&gt; org.apache.iceberg.spark.SparkTableUtil.listPartition</definition>
        <argsstring>(SparkPartition partition, PartitionSpec spec, SerializableConfiguration conf, MetricsConfig metricsConfig, NameMapping mapping)</argsstring>
        <name>listPartition</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
          <declname>partition</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1MetricsConfig" kindref="compound">MetricsConfig</ref></type>
          <declname>metricsConfig</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1mapping_1_1NameMapping" kindref="compound">NameMapping</ref></type>
          <declname>mapping</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns the data files in a partition by listing the partition location.</para>
<para>For Parquet and ORC partitions, this will read metrics from the file footer. For Avro partitions, metrics are set to null.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>partition</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>conf</parametername>
</parameternamelist>
<parameterdescription>
<para>a serializable Hadoop conf </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>metricsConfig</parametername>
</parameternamelist>
<parameterdescription>
<para>a metrics conf </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>mapping</parametername>
</parameternamelist>
<parameterdescription>
<para>a name mapping </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a List of <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> </para>
</simplesect>
<xrefsect id="deprecated_1_deprecated000064"><xreftitle>Deprecated</xreftitle><xrefdescription><para>use <ref refid="" kindref="compound">String, String, PartitionSpec, Configuration, MetricsConfig, NameMapping)</ref> </para>
</xrefdescription></xrefsect></para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="312" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="312" bodyend="326"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, Map&lt; String, String &gt; partitionFilter, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>only import partitions whose values match those in the map, can be partially defined </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="415" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="415" bodyend="457"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="471" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="471" bodyend="484"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="497" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="497" bodyend="501"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="573" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="573" bodyend="658"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="669" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="669" bodyend="676"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.filterPartitions</definition>
        <argsstring>(List&lt; SparkPartition &gt; partitions, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>filterPartitions</name>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="678" column="22" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="678" bodyend="687"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a817ef44dae21378138535dd1d24fcaf7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadCatalogMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type)</argsstring>
        <name>loadCatalogMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Loads a metadata table.</para>
<para><xrefsect id="deprecated_1_deprecated000065"><xreftitle>Deprecated</xreftitle><xrefdescription><para>since 0.14.0, will be removed in 0.15.0; use {<ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" kindref="member">}. </ref></para>
</xrefdescription></xrefsect></para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="704" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="704" bodyend="707"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="709" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="709" bodyend="712"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type, Map&lt; String, String &gt; extraOptions)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>extraOptions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="714" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="714" bodyend="721"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>String</type>
        <definition>static String org.apache.iceberg.spark.SparkTableUtil.determineWriteBranch</definition>
        <argsstring>(SparkSession spark, String branch)</argsstring>
        <name>determineWriteBranch</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>branch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Determine the write branch.</para>
<para>Validate wap config and determine the write branch.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark Session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>branch</parametername>
</parameternamelist>
<parameterdescription>
<para>write branch if there is no WAP branch configured </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>branch for write operation </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="732" column="24" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="732" bodyend="751"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>static boolean org.apache.iceberg.spark.SparkTableUtil.wapEnabled</definition>
        <argsstring>(Table table)</argsstring>
        <name>wapEnabled</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="753" column="25" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="753" bodyend="758"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDF</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>partitionDF</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition in the table.</para>
<para>The DataFrame has 3 columns, partition key (a=1/b=2), partition location, and format (avro or parquet).</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="128" column="25" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="128" bodyend="133"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDFByFilter</definition>
        <argsstring>(SparkSession spark, String table, String expression)</argsstring>
        <name>partitionDFByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>expression</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition that matches the specified &apos;expression&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>name of the table. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>expression</parametername>
</parameternamelist>
<parameterdescription>
<para>The expression whose matching partitions are returned. </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table partitions. </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="143" column="25" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="143" bodyend="149"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="158" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="158" bodyend="166"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>partition filter, or null if no filter </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="176" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="176" bodyend="203"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, String table, String predicate)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>predicate</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicate</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="213" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="213" bodyend="233"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Expression predicateExpr)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>predicateExpr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicateExpr</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate expression on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="243" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="243" bodyend="273"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, Map&lt; String, String &gt; partitionFilter, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>only import partitions whose values match those in the map, can be partially defined </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="378" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="378" bodyend="420"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="434" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="434" bodyend="447"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="460" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="460" bodyend="464"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="536" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="536" bodyend="621"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="632" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="632" bodyend="639"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.filterPartitions</definition>
        <argsstring>(List&lt; SparkPartition &gt; partitions, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>filterPartitions</name>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="641" column="22" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="641" bodyend="650"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="660" column="25" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="660" bodyend="663"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type, Map&lt; String, String &gt; extraOptions)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>extraOptions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="665" column="25" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="665" bodyend="672"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>String</type>
        <definition>static String org.apache.iceberg.spark.SparkTableUtil.determineWriteBranch</definition>
        <argsstring>(SparkSession spark, String branch)</argsstring>
        <name>determineWriteBranch</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>branch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Determine the write branch.</para>
<para>Validate wap config and determine the write branch.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark Session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>branch</parametername>
</parameternamelist>
<parameterdescription>
<para>write branch if there is no WAP branch configured </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>branch for write operation </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="683" column="24" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="683" bodyend="702"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>static boolean org.apache.iceberg.spark.SparkTableUtil.wapEnabled</definition>
        <argsstring>(Table table)</argsstring>
        <name>wapEnabled</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="704" column="25" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="704" bodyend="709"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDF</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>partitionDF</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition in the table.</para>
<para>The DataFrame has 3 columns, partition key (a=1/b=2), partition location, and format (avro or parquet).</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="128" column="25" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="128" bodyend="133"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.partitionDFByFilter</definition>
        <argsstring>(SparkSession spark, String table, String expression)</argsstring>
        <name>partitionDFByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>expression</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns a DataFrame with a row for each partition that matches the specified &apos;expression&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>name of the table. </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>expression</parametername>
</parameternamelist>
<parameterdescription>
<para>The expression whose matching partitions are returned. </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>a DataFrame of the table partitions. </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="143" column="25" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="143" bodyend="149"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, String table)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="158" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="158" bodyend="166"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitions</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>getPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns all partitions in the table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>partition filter, or null if no filter </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>all table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="176" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="176" bodyend="203"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, String table, String predicate)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type>String</type>
          <declname>predicate</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>table</parametername>
</parameternamelist>
<parameterdescription>
<para>a table name and (optional) database </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicate</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="213" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="213" bodyend="233"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.getPartitionsByFilter</definition>
        <argsstring>(SparkSession spark, TableIdentifier tableIdent, Expression predicateExpr)</argsstring>
        <name>getPartitionsByFilter</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>tableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>predicateExpr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Returns partitions that match the specified &apos;predicate&apos;.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>a table identifier </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>predicateExpr</parametername>
</parameternamelist>
<parameterdescription>
<para>a predicate expression on partition columns </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>matching table&apos;s partitions </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="243" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="243" bodyend="273"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, Map&lt; String, String &gt; partitionFilter, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>only import partitions whose values match those in the map, can be partially defined </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="380" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="380" bodyend="389"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a4440d44b1523aa8e983c545f16da5a34" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, Map&lt; String, String &gt; partitionFilter, boolean checkDuplicateFiles, int parallelism)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <param>
          <type>int</type>
          <declname>parallelism</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitionFilter</parametername>
</parameternamelist>
<parameterdescription>
<para>only import partitions whose values match those in the map, can be partially defined </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>parallelism</parametername>
</parameternamelist>
<parameterdescription>
<para>number of threads to use for file reading </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="406" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="406" bodyend="455"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="469" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="469" bodyend="483"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, String stagingDir)</argsstring>
        <name>importSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from an existing Spark table to an Iceberg table.</para>
<para>The import uses the Spark session to get table metadata. It assumes no operation is going on the original and target table and thus is not thread-safe.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>sourceTableIdent</parametername>
</parameternamelist>
<parameterdescription>
<para>an identifier of the source Spark table </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="496" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="496" bodyend="500"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir, boolean checkDuplicateFiles)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="574" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="574" bodyend="582"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ae75e0c8bb5e3cf4dd3f9f3a669d126ed" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir, boolean checkDuplicateFiles, int parallelism)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <param>
          <type>int</type>
          <declname>parallelism</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>checkDuplicateFiles</parametername>
</parameternamelist>
<parameterdescription>
<para>if true, throw exception if import results in a duplicate data file </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>parallelism</parametername>
</parameternamelist>
<parameterdescription>
<para>number of threads to use for file reading </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="595" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="595" bodyend="686"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importSparkPartitions</definition>
        <argsstring>(SparkSession spark, List&lt; SparkPartition &gt; partitions, Table targetTable, PartitionSpec spec, String stagingDir)</argsstring>
        <name>importSparkPartitions</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>stagingDir</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Import files from given partitions to an Iceberg table.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>partitions</parametername>
</parameternamelist>
<parameterdescription>
<para>partitions to import </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>targetTable</parametername>
</parameternamelist>
<parameterdescription>
<para>an Iceberg table where to import the data </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>spec</parametername>
</parameternamelist>
<parameterdescription>
<para>a partition spec </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>stagingDir</parametername>
</parameternamelist>
<parameterdescription>
<para>a staging directory to store temporary manifest files </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="697" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="697" bodyend="704"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
        <definition>static List&lt;SparkPartition&gt; org.apache.iceberg.spark.SparkTableUtil.filterPartitions</definition>
        <argsstring>(List&lt; SparkPartition &gt; partitions, Map&lt; String, String &gt; partitionFilter)</argsstring>
        <name>filterPartitions</name>
        <param>
          <type>List&lt; <ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref> &gt;</type>
          <declname>partitions</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>partitionFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="706" column="22" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="706" bodyend="715"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="725" column="25" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="725" bodyend="728"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Dataset&lt; Row &gt;</type>
        <definition>static Dataset&lt;Row&gt; org.apache.iceberg.spark.SparkTableUtil.loadMetadataTable</definition>
        <argsstring>(SparkSession spark, Table table, MetadataTableType type, Map&lt; String, String &gt; extraOptions)</argsstring>
        <name>loadMetadataTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1MetadataTableType" kindref="compound">MetadataTableType</ref></type>
          <declname>type</declname>
        </param>
        <param>
          <type>Map&lt; String, String &gt;</type>
          <declname>extraOptions</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="730" column="25" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="730" bodyend="737"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>String</type>
        <definition>static String org.apache.iceberg.spark.SparkTableUtil.determineWriteBranch</definition>
        <argsstring>(SparkSession spark, String branch)</argsstring>
        <name>determineWriteBranch</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>branch</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para>Determine the write branch.</para>
<para>Validate wap config and determine the write branch.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>spark</parametername>
</parameternamelist>
<parameterdescription>
<para>a Spark Session </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>branch</parametername>
</parameternamelist>
<parameterdescription>
<para>write branch if there is no WAP branch configured </para>
</parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>branch for write operation </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="748" column="24" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="748" bodyend="767"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>boolean</type>
        <definition>static boolean org.apache.iceberg.spark.SparkTableUtil.wapEnabled</definition>
        <argsstring>(Table table)</argsstring>
        <name>wapEnabled</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="769" column="25" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="769" bodyend="774"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="private-static-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
        <definition>static SparkPartition org.apache.iceberg.spark.SparkTableUtil.toSparkPartition</definition>
        <argsstring>(CatalogTablePartition partition, CatalogTable table)</argsstring>
        <name>toSparkPartition</name>
        <param>
          <type>CatalogTablePartition</type>
          <declname>partition</declname>
        </param>
        <param>
          <type>CatalogTable</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="328" column="33" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="328" bodyend="343"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
        <definition>static Expression org.apache.iceberg.spark.SparkTableUtil.resolveAttrs</definition>
        <argsstring>(SparkSession spark, String table, Expression expr)</argsstring>
        <name>resolveAttrs</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>expr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="345" column="29" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="345" bodyend="368"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Iterator&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
        <definition>static Iterator&lt;ManifestFile&gt; org.apache.iceberg.spark.SparkTableUtil.buildManifest</definition>
        <argsstring>(SerializableConfiguration conf, PartitionSpec spec, String basePath, Iterator&lt; Tuple2&lt; String, DataFile &gt;&gt; fileTuples)</argsstring>
        <name>buildManifest</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>basePath</declname>
        </param>
        <param>
          <type>Iterator&lt; Tuple2&lt; String, <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;&gt;</type>
          <declname>fileTuples</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="370" column="27" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="370" bodyend="399"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ace67ee8b893f73b27e9943707e1b5a26" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importUnpartitionedSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, boolean checkDuplicateFiles)</argsstring>
        <name>importUnpartitionedSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="503" column="23" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="503" bodyend="561"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.deleteManifests</definition>
        <argsstring>(FileIO io, List&lt; ManifestFile &gt; manifests)</argsstring>
        <name>deleteManifests</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1FileIO" kindref="compound">FileIO</ref></type>
          <declname>io</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
          <declname>manifests</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="689" column="23" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="689" bodyend="695"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab6335c5079cb1e674019784cf50a0776" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;</type>
        <definition>static List&lt;DataFile&gt; org.apache.iceberg.spark.SparkTableUtil.listPartition</definition>
        <argsstring>(SparkPartition partition, PartitionSpec spec, SerializableConfiguration conf, MetricsConfig metricsConfig, NameMapping mapping)</argsstring>
        <name>listPartition</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
          <declname>partition</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1MetricsConfig" kindref="compound">MetricsConfig</ref></type>
          <declname>metricsConfig</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1mapping_1_1NameMapping" kindref="compound">NameMapping</ref></type>
          <declname>mapping</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="275" column="23" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="275" bodyend="289"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
        <definition>static SparkPartition org.apache.iceberg.spark.SparkTableUtil.toSparkPartition</definition>
        <argsstring>(CatalogTablePartition partition, CatalogTable table)</argsstring>
        <name>toSparkPartition</name>
        <param>
          <type>CatalogTablePartition</type>
          <declname>partition</declname>
        </param>
        <param>
          <type>CatalogTable</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="291" column="33" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="291" bodyend="306"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
        <definition>static Expression org.apache.iceberg.spark.SparkTableUtil.resolveAttrs</definition>
        <argsstring>(SparkSession spark, String table, Expression expr)</argsstring>
        <name>resolveAttrs</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>expr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="308" column="29" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="308" bodyend="331"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Iterator&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
        <definition>static Iterator&lt;ManifestFile&gt; org.apache.iceberg.spark.SparkTableUtil.buildManifest</definition>
        <argsstring>(SerializableConfiguration conf, PartitionSpec spec, String basePath, Iterator&lt; Tuple2&lt; String, DataFile &gt;&gt; fileTuples)</argsstring>
        <name>buildManifest</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>basePath</declname>
        </param>
        <param>
          <type>Iterator&lt; Tuple2&lt; String, <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;&gt;</type>
          <declname>fileTuples</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="333" column="27" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="333" bodyend="362"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ace67ee8b893f73b27e9943707e1b5a26" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importUnpartitionedSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, boolean checkDuplicateFiles)</argsstring>
        <name>importUnpartitionedSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="466" column="23" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="466" bodyend="524"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.deleteManifests</definition>
        <argsstring>(FileIO io, List&lt; ManifestFile &gt; manifests)</argsstring>
        <name>deleteManifests</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1FileIO" kindref="compound">FileIO</ref></type>
          <declname>io</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
          <declname>manifests</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="652" column="23" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="652" bodyend="658"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1aeb1c47672ecf6f30a3ed9084f158c859" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;</type>
        <definition>static List&lt;DataFile&gt; org.apache.iceberg.spark.SparkTableUtil.listPartition</definition>
        <argsstring>(SparkPartition partition, PartitionSpec spec, SerializableConfiguration conf, MetricsConfig metricsConfig, NameMapping mapping, int parallelism)</argsstring>
        <name>listPartition</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
          <declname>partition</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1MetricsConfig" kindref="compound">MetricsConfig</ref></type>
          <declname>metricsConfig</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1mapping_1_1NameMapping" kindref="compound">NameMapping</ref></type>
          <declname>mapping</declname>
        </param>
        <param>
          <type>int</type>
          <declname>parallelism</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="275" column="23" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="275" bodyend="291"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1_1SparkPartition" kindref="compound">SparkPartition</ref></type>
        <definition>static SparkPartition org.apache.iceberg.spark.SparkTableUtil.toSparkPartition</definition>
        <argsstring>(CatalogTablePartition partition, CatalogTable table)</argsstring>
        <name>toSparkPartition</name>
        <param>
          <type>CatalogTablePartition</type>
          <declname>partition</declname>
        </param>
        <param>
          <type>CatalogTable</type>
          <declname>table</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="293" column="33" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="293" bodyend="308"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
        <definition>static Expression org.apache.iceberg.spark.SparkTableUtil.resolveAttrs</definition>
        <argsstring>(SparkSession spark, String table, Expression expr)</argsstring>
        <name>resolveAttrs</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type>String</type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>expr</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="310" column="29" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="310" bodyend="333"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>Iterator&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
        <definition>static Iterator&lt;ManifestFile&gt; org.apache.iceberg.spark.SparkTableUtil.buildManifest</definition>
        <argsstring>(SerializableConfiguration conf, PartitionSpec spec, String basePath, Iterator&lt; Tuple2&lt; String, DataFile &gt;&gt; fileTuples)</argsstring>
        <name>buildManifest</name>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1hadoop_1_1SerializableConfiguration" kindref="compound">SerializableConfiguration</ref></type>
          <declname>conf</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1PartitionSpec" kindref="compound">PartitionSpec</ref></type>
          <declname>spec</declname>
        </param>
        <param>
          <type>String</type>
          <declname>basePath</declname>
        </param>
        <param>
          <type>Iterator&lt; Tuple2&lt; String, <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1DataFile" kindref="compound">DataFile</ref> &gt;&gt;</type>
          <declname>fileTuples</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="335" column="27" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="335" bodyend="364"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a9ac662c5f7433fb60e37907c8d03fc4b" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.importUnpartitionedSparkTable</definition>
        <argsstring>(SparkSession spark, TableIdentifier sourceTableIdent, Table targetTable, boolean checkDuplicateFiles, int parallelism)</argsstring>
        <name>importUnpartitionedSparkTable</name>
        <param>
          <type>SparkSession</type>
          <declname>spark</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1catalog_1_1TableIdentifier" kindref="compound">TableIdentifier</ref></type>
          <declname>sourceTableIdent</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>targetTable</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>checkDuplicateFiles</declname>
        </param>
        <param>
          <type>int</type>
          <declname>parallelism</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="502" column="23" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="502" bodyend="562"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void org.apache.iceberg.spark.SparkTableUtil.deleteManifests</definition>
        <argsstring>(FileIO io, List&lt; ManifestFile &gt; manifests)</argsstring>
        <name>deleteManifests</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1FileIO" kindref="compound">FileIO</ref></type>
          <declname>io</declname>
        </param>
        <param>
          <type>List&lt; <ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ManifestFile" kindref="compound">ManifestFile</ref> &gt;</type>
          <declname>manifests</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="717" column="23" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="717" bodyend="723"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>Java version of the original SparkTableUtil.scala <ulink url="https://github.com/apache/iceberg/blob/apache-iceberg-0.8.0-incubating/spark/src/main/scala/org/apache/iceberg/spark/SparkTableUtil.scala">https://github.com/apache/iceberg/blob/apache-iceberg-0.8.0-incubating/spark/src/main/scala/org/apache/iceberg/spark/SparkTableUtil.scala</ulink> </para>
    </detaileddescription>
    <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" line="108" column="28" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java" bodystart="108" bodyend="812"/>
    <listofallmembers>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>buildManifest</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>buildManifest</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab027fe46415e862f3f17428a681b6629" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>buildManifest</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>deleteManifests</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>deleteManifests</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5f291d27b3d05e7c39e7c7b73e8e6181" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>deleteManifests</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>determineWriteBranch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>determineWriteBranch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a34aec7242776222e4d2df57f291bccf1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>determineWriteBranch</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a701fbb8197f26a0464822d0aa3093efa" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>DUPLICATE_FILE_MESSAGE</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>filterPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>filterPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a115b4ddf4c8ca25dbeec69470aec4f16" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>filterPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab0eeb735bbedd38bcd77ed09d0001eb8" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a85b2c094f35664c1f2994ecb6949ae8f" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a96532ec81143af827a972c4d800cc96a" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a84447c7f62390aa7558d5e3c8a8711d7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>getPartitionsByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6b6241fd3ad5fa54843c2d360e58b820" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ae75e0c8bb5e3cf4dd3f9f3a669d126ed" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8e1251944faaacb11d13bb3d9ac6d9d1" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkPartitions</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a3c42c33afb1e1998966a30b9b0e18e41" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a4440d44b1523aa8e983c545f16da5a34" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ac625c44019a44479a6d6d7ac1e4eea95" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a26dd40cc9b82d7ac74479dabd0a6cdf6" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ace67ee8b893f73b27e9943707e1b5a26" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importUnpartitionedSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ace67ee8b893f73b27e9943707e1b5a26" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importUnpartitionedSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a9ac662c5f7433fb60e37907c8d03fc4b" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>importUnpartitionedSparkTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a7b75e0408be23eda1b7dec6c73f0bb19" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>listPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab6335c5079cb1e674019784cf50a0776" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>listPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1ab6335c5079cb1e674019784cf50a0776" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>listPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1aeb1c47672ecf6f30a3ed9084f158c859" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>listPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a817ef44dae21378138535dd1d24fcaf7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadCatalogMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a48cfcab99444ffbf7f39245d9fb6de2b" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a5923b06525772b75ea4f984348971513" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>loadMetadataTable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDF</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDF</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8aa77951ef21354be135a05d05554cc7" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDF</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDFByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDFByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1af5285fabfe5463601def6422b25c3096" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>partitionDFByFilter</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>resolveAttrs</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>resolveAttrs</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acf7cc94933d5d4d4d640da7e70a248e2" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>resolveAttrs</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>SparkTableUtil</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>SparkTableUtil</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a6c45180d23dac6c4b3a0e1073c08c91c" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>SparkTableUtil</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>toSparkPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>toSparkPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1acda950032aa68094075046430a014fc9" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>toSparkPartition</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>wapEnabled</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>wapEnabled</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1SparkTableUtil_1a8b0b3df097da20bc496607bd63177cdb" prot="public" virt="non-virtual"><scope>org::apache::iceberg::spark::SparkTableUtil</scope><name>wapEnabled</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
