<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.17">
  <compounddef id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader" kind="class" language="Java" prot="package" abstract="yes">
    <compoundname>org::apache::iceberg::spark::source::BaseBatchReader</compoundname>
    <basecompoundref prot="public" virt="non-virtual">org::apache::iceberg::spark::source::BaseReader&lt; ColumnarBatch, T &gt;</basecompoundref>
    <templateparamlist>
      <param>
        <type>T</type>
        <typeconstraint><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ScanTask" kindref="compound">ScanTask</ref></typeconstraint>
      </param>
    </templateparamlist>
      <sectiondef kind="private-attrib">
      <memberdef kind="variable" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6a7708be6080fc1818a8fd6a85b5928e" prot="private" static="no" mutable="no">
        <type>final int</type>
        <definition>final int org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;::batchSize</definition>
        <argsstring></argsstring>
        <name>batchSize</name>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="41" column="21" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="41" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="package-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.BaseBatchReader</definition>
        <argsstring>(Table table, ScanTaskGroup&lt; T &gt; taskGroup, Schema tableSchema, Schema expectedSchema, boolean caseSensitive, int batchSize)</argsstring>
        <name>BaseBatchReader</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ScanTaskGroup" kindref="compound">ScanTaskGroup</ref>&lt; T &gt;</type>
          <declname>taskGroup</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>tableSchema</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>expectedSchema</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>caseSensitive</declname>
        </param>
        <param>
          <type>int</type>
          <declname>batchSize</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="43" column="3" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="43" bodyend="52"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.BaseBatchReader</definition>
        <argsstring>(Table table, ScanTaskGroup&lt; T &gt; taskGroup, Schema tableSchema, Schema expectedSchema, boolean caseSensitive, int batchSize)</argsstring>
        <name>BaseBatchReader</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ScanTaskGroup" kindref="compound">ScanTaskGroup</ref>&lt; T &gt;</type>
          <declname>taskGroup</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>tableSchema</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>expectedSchema</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>caseSensitive</declname>
        </param>
        <param>
          <type>int</type>
          <declname>batchSize</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="43" column="3" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="43" bodyend="52"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.BaseBatchReader</definition>
        <argsstring>(Table table, ScanTaskGroup&lt; T &gt; taskGroup, Schema tableSchema, Schema expectedSchema, boolean caseSensitive, int batchSize)</argsstring>
        <name>BaseBatchReader</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1Table" kindref="compound">Table</ref></type>
          <declname>table</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1ScanTaskGroup" kindref="compound">ScanTaskGroup</ref>&lt; T &gt;</type>
          <declname>taskGroup</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>tableSchema</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1Schema" kindref="compound">Schema</ref></type>
          <declname>expectedSchema</declname>
        </param>
        <param>
          <type>boolean</type>
          <declname>caseSensitive</declname>
        </param>
        <param>
          <type>int</type>
          <declname>batchSize</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="43" column="3" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="43" bodyend="52"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="protected-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newBatchIterable</definition>
        <argsstring>(InputFile inputFile, FileFormat format, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newBatchIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1FileFormat" kindref="compound">FileFormat</ref></type>
          <declname>format</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="54" column="31" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="54" bodyend="73"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newBatchIterable</definition>
        <argsstring>(InputFile inputFile, FileFormat format, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newBatchIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1FileFormat" kindref="compound">FileFormat</ref></type>
          <declname>format</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="54" column="31" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="54" bodyend="73"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newBatchIterable</definition>
        <argsstring>(InputFile inputFile, FileFormat format, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newBatchIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type><ref refid="enumorg_1_1apache_1_1iceberg_1_1FileFormat" kindref="compound">FileFormat</ref></type>
          <declname>format</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="54" column="31" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="54" bodyend="73"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="private-func">
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newParquetIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newParquetIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="75" column="29" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="75" bodyend="101"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newOrcIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant)</argsstring>
        <name>newOrcIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="103" column="29" bodyfile="spark/v3.3/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="103" bodyend="127"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newParquetIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newParquetIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="75" column="29" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="75" bodyend="101"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newOrcIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant)</argsstring>
        <name>newOrcIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="103" column="29" bodyfile="spark/v3.4/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="103" bodyend="127"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newParquetIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant, SparkDeleteFilter deleteFilter)</argsstring>
        <name>newParquetIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <param>
          <type><ref refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseReader_1_1SparkDeleteFilter" kindref="compound">SparkDeleteFilter</ref></type>
          <declname>deleteFilter</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="75" column="29" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="75" bodyend="101"/>
      </memberdef>
      <memberdef kind="function" id="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1CloseableIterable" kindref="compound">CloseableIterable</ref>&lt; ColumnarBatch &gt;</type>
        <definition>CloseableIterable&lt;ColumnarBatch&gt; org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;.newOrcIterable</definition>
        <argsstring>(InputFile inputFile, long start, long length, Expression residual, Map&lt; Integer, ?&gt; idToConstant)</argsstring>
        <name>newOrcIterable</name>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1io_1_1InputFile" kindref="compound">InputFile</ref></type>
          <declname>inputFile</declname>
        </param>
        <param>
          <type>long</type>
          <declname>start</declname>
        </param>
        <param>
          <type>long</type>
          <declname>length</declname>
        </param>
        <param>
          <type><ref refid="interfaceorg_1_1apache_1_1iceberg_1_1expressions_1_1Expression" kindref="compound">Expression</ref></type>
          <declname>residual</declname>
        </param>
        <param>
          <type>Map&lt; Integer, ?&gt;</type>
          <declname>idToConstant</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="103" column="29" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="103" bodyend="127"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <inheritancegraph>
      <node id="2">
        <label>org::apache::iceberg::spark::source::BaseReader&lt; ColumnarBatch, T &gt;</label>
      </node>
      <node id="1">
        <label>org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;</label>
        <childnode refid="2" relation="public-inheritance">
        </childnode>
      </node>
    </inheritancegraph>
    <collaborationgraph>
      <node id="2">
        <label>org::apache::iceberg::spark::source::BaseReader&lt; ColumnarBatch, T &gt;</label>
      </node>
      <node id="1">
        <label>org.apache.iceberg.spark.source.BaseBatchReader&lt; T extends ScanTask &gt;</label>
        <childnode refid="2" relation="public-inheritance">
        </childnode>
      </node>
    </collaborationgraph>
    <location file="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" line="40" column="45" bodyfile="spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/source/BaseBatchReader.java" bodystart="40" bodyend="128"/>
    <listofallmembers>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>BaseBatchReader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>BaseBatchReader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a87310e5767e609040370bf6ebbff7de0" prot="package" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>BaseBatchReader</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6a7708be6080fc1818a8fd6a85b5928e" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>batchSize</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newBatchIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newBatchIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a6d8b971f5ebcba0ce12efdbaa0c2ddb7" prot="protected" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newBatchIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newOrcIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newOrcIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1afa882e93e0bf6d22922856a546a295ab" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newOrcIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newParquetIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newParquetIterable</name></member>
      <member refid="classorg_1_1apache_1_1iceberg_1_1spark_1_1source_1_1BaseBatchReader_1a5a9d98d5388b50f57ee4213235b2ecd6" prot="private" virt="non-virtual"><scope>org::apache::iceberg::spark::source::BaseBatchReader</scope><name>newParquetIterable</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
